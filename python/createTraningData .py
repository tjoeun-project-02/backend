import os
import glob
import json
import time
import pandas as pd
from tqdm import tqdm
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# ======================================================
# [0] API í‚¤ ë° ëª¨ë¸ ì„¤ì •
# ======================================================
# ğŸš¨ [ì—¬ê¸°!] ë”°ì˜´í‘œ ì•ˆì— ì§„ì§œ API í‚¤ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš” (AIza...)
MY_API_KEY = ""  

if MY_API_KEY == "YOUR_API_KEY_HERE" or MY_API_KEY == "ì—¬ê¸°ì—_ì§„ì§œ_í‚¤ë¥¼_ë¶™ì—¬ë„£ìœ¼ì„¸ìš”":
    print("âŒ [ì˜¤ë¥˜] API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! ì½”ë“œ 15ë²ˆì§¸ ì¤„ì„ í™•ì¸í•˜ì„¸ìš”.")
    exit() # í”„ë¡œê·¸ë¨ ì¢…ë£Œ

try:
    genai.configure(api_key=MY_API_KEY)
except Exception as e:
    print(f"âŒ [ì„¤ì • ì˜¤ë¥˜] API í‚¤ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
    exit()

MODEL_NAME = 'gemini-2.5-flash-lite'
model = genai.GenerativeModel(MODEL_NAME)

# ì•ˆì „ í•„í„° í•´ì œ
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

print(f"ğŸ”§ ëª¨ë¸ ì„¤ì • ì™„ë£Œ: {MODEL_NAME} (ì•ˆì „ í•„í„° í•´ì œë¨)")

# ======================================================
# [1] íŒŒì¼ ê²½ë¡œ ì„¤ì • (Mac ë¡œì»¬ ê²½ë¡œ)
# ======================================================
json_folder_path = '/Users/ljw/Desktop/whisky_assistant/crawlers/data/raw'
save_path = '/Users/ljw/Desktop/whisky_assistant/crawlers/data/whisky_training_data.csv'
BATCH_SIZE = 20
TEST_LIMIT = None 

print(f"ğŸ“‚ ì½ì–´ì˜¬ í´ë”: {json_folder_path}")
print(f"ğŸ’¾ ì €ì¥í•  íŒŒì¼: {save_path}")

# ======================================================
# [2] ì—°ê²° í…ŒìŠ¤íŠ¸ (í‚¤ ì˜¤ë¥˜ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨ ê¸°ëŠ¥ ì¶”ê°€)
# ======================================================
print("\nğŸ“¡ [í…ŒìŠ¤íŠ¸] API ì—°ê²° ì‹œë„ ì¤‘...", end=" ", flush=True)
while True:
    try:
        model.generate_content("Hi", request_options={"timeout": 30})
        print("âœ… ì„±ê³µ! (ì—°ê²°ë¨)")
        break 
    except Exception as e:
        error_msg = str(e)
        # ğŸš¨ API í‚¤ê°€ í‹€ë ¸ìœ¼ë©´ ì¬ì‹œë„í•˜ì§€ ì•Šê³  ë°”ë¡œ ë©ˆì¶¤!
        if "400" in error_msg or "API key" in error_msg or "API_KEY_INVALID" in error_msg:
            print(f"\n\nâŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] API í‚¤ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            print(f"ğŸ‘‰ ì›ì¸: {error_msg}")
            print("ğŸ‘‰ í•´ê²°: ì½”ë“œ ìƒë‹¨ì˜ 'MY_API_KEY' ë³€ìˆ˜ì— ì •í™•í•œ í‚¤ë¥¼ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            exit() # í”„ë¡œê·¸ë¨ ê°•ì œ ì¢…ë£Œ
            
        print(f"\nâš ï¸ [ì—°ê²° ì§€ì—°] {e}")
        print("â³ ë„¤íŠ¸ì›Œí¬/API ë¶ˆì•ˆì •. 5ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...", end=" ", flush=True)
        time.sleep(5)
        print("ì¬ì‹œë„!")

# ======================================================
# [3] ë°°ì¹˜ ë¶„ì„ í•¨ìˆ˜
# ======================================================
def analyze_batch_reviews(review_list):
    formatted_reviews = ""
    for idx, r_text in enumerate(review_list):
        formatted_reviews += f"""
        [Review {idx+1}]
        "{r_text}"
        --------------------------------------------------
        """

    prompt = f"""
    ë„ˆëŠ” ìœ„ìŠ¤í‚¤ ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” 'ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸'ì•¼.
    ì•„ë˜ ì œê³µëœ {len(review_list)}ê°œì˜ ìœ„ìŠ¤í‚¤ ë¦¬ë·°(Review 1 ~ Review {len(review_list)})ë¥¼ ê°ê° ë¶„ì„í•´ì„œ ì •ëŸ‰ì ì¸ ìˆ˜ì¹˜ë¡œ ë³€í™˜í•´ì¤˜.

    [ë¶„ì„ ê·œì¹™ - ë§¤ìš° ì¤‘ìš”]
    1. **ë¹ˆë„(Frequency)ì™€ ê°•ë„(Intensity) ê¸°ë°˜ ì±„ì **:
       - ë¦¬ë·°ì—ì„œ íŠ¹ì • ë§›ì´ ì–¼ë§ˆë‚˜ ìì£¼, ì–¼ë§ˆë‚˜ ê°•í•˜ê²Œ ì–¸ê¸‰ë˜ëŠ”ì§€ ë¶„ì„í•´ë¼.

    2. **ë™ì˜ì–´ ë° í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (Smart Mapping)**:
       - í…ìŠ¤íŠ¸ì— ì¹´í…Œê³ ë¦¬ ë‹¨ì–´ê°€ ì§ì ‘ì ìœ¼ë¡œ ì—†ì–´ë„, **ì—°ê´€ëœ ë§›ì´ë‚˜ í•˜ìœ„ ê°œë…ì´ ìˆìœ¼ë©´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì ìˆ˜ì— ë°˜ì˜í•´ë¼.**
       - ì˜ˆì‹œ 1: "ë³µìˆ­ì•„", "ì‚´êµ¬", "ìë‘", "í•µê³¼ë¥˜", "ë² ë¦¬" -> **Fruity** ì ìˆ˜ ì¦ê°€
       - ì˜ˆì‹œ 2: "í† í”¼", "í‘ì„¤íƒ•", "ë©”ì´í”Œ ì‹œëŸ½", "í¬ë¦¼ ë¸Œë¥„ë ˆ" -> **Sweet** ì ìˆ˜ ì¦ê°€
       - ì˜ˆì‹œ 3: "ë³‘ì› ëƒ„ìƒˆ", "ìš”ì˜¤ë“œ", "í›ˆì œ ì—°ì–´", "íƒ€ì´ì–´ ê³ ë¬´" -> **Peaty** ì ìˆ˜ ì¦ê°€
       - ì˜ˆì‹œ 4: "í›„ì¶”", "ìƒê°•", "ì •í–¥", "ì•Œì‹¸í•œ" -> **Spicy** ì ìˆ˜ ì¦ê°€
       - ì˜ˆì‹œ 5: "í†±ë°¥", "ì˜¤ë˜ëœ ê°€êµ¬", "íƒ„ë‹Œ", "ì”ì“¸í•œ" -> **Woody** ì ìˆ˜ ì¦ê°€
       - ì˜ˆì‹œ 6: "ë¹„ìŠ¤í‚·", "í† ìŠ¤íŠ¸", "ì‹œë¦¬ì–¼", "êµ¬ìš´ ë¹µ" -> **Malty** ì ìˆ˜ ì¦ê°€

    3. **ì ìˆ˜ ê¸°ì¤€**:
       - 0ì : í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì™€ ê´€ë ¨ëœ ë‹¨ì–´ë‚˜ ë‰˜ì•™ìŠ¤ê°€ ì „í˜€ ì—†ìŒ.
       - 1~3ì : ë¯¸ë¯¸í•˜ê±°ë‚˜ ë°°ê²½ì— ê¹”ë¦¬ëŠ” ì •ë„.
       - 4~6ì : ë¶„ëª…í•˜ê²Œ ëŠê»´ì§€ì§€ë§Œ ì••ë„ì ì´ì§€ ì•ŠìŒ.
       - 7~9ì : í•´ë‹¹ ìœ„ìŠ¤í‚¤ì˜ ì§€ë°°ì ì¸(Dominant) ìºë¦­í„°ì„.
       - 10ì : "ì´ ìœ„ìŠ¤í‚¤ëŠ” ê³§ ì´ ë§›ì´ë‹¤"ë¼ê³  í•  ì •ë„ë¡œ ê°•ë ¬í•¨ (ì˜ˆ: ì•„ë“œë²¡ì˜ í”¼íŠ¸).

    [ì…ë ¥ ë°ì´í„°]
    {formatted_reviews}

    [ì¶œë ¥ í¬ë§· (JSON List only)]
    ë°˜ë“œì‹œ ì…ë ¥ëœ ë¦¬ë·° ìˆœì„œëŒ€ë¡œ {len(review_list)}ê°œì˜ ê°ì²´ë¥¼ ê°€ì§„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•´.
    [
        {{
            "fruity": 0~10,
            "sweet": 0~10,
            "peaty": 0~10,
            "spicy": 0~10,
            "woody": 0~10,
            "malty": 0~10,
            "review_sentiment": -1.0 ~ 1.0,
            "flavor_tags": ["ì¶”ì¶œëœ í•µì‹¬ ë§›1", "í•µì‹¬ ë§›2", "í•µì‹¬ ë§›3", "í•µì‹¬ ë§›4", "í•µì‹¬ ë§›5"]
        }},
        ... (ë°˜ë³µ)
    ]
    """

    while True:
        try:
            response = model.generate_content(prompt, safety_settings=safety_settings, request_options={"timeout": 50})
            text_res = response.text.replace("```json", "").replace("```", "").strip()
            
            results = json.loads(text_res)
            
            if isinstance(results, list) and len(results) == len(review_list):
                return results
            else:
                time.sleep(2)
                continue

        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "503" in error_msg:
                print(f"\nâ³ [ëŒ€ê¸°] ì†ë„ ì œí•œ. 40ì´ˆ ì‰¼...", end=" ", flush=True)
                time.sleep(40)
            else:
                print(f"\nâš ï¸ ë°°ì¹˜ ì—ëŸ¬: {e} -> 5ì´ˆ í›„ ì¬ì‹œë„")
                time.sleep(5)
            continue

# ======================================================
# [4] ë©”ì¸ ì‹¤í–‰ ë¡œì§
# ======================================================
if __name__ == "__main__":
    json_files = glob.glob(os.path.join(json_folder_path, "*.json"))
    print(f"ğŸ“‚ ì´ {len(json_files)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    if TEST_LIMIT:
        json_files = json_files[:TEST_LIMIT]

    training_data = []

    if os.path.exists(save_path):
        try:
            existing_df = pd.read_csv(save_path)
            training_data = existing_df.to_dict('records')
            print(f"ğŸ”„ ê¸°ì¡´ ë°ì´í„° {len(training_data)}ê°œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except:
            pass

    for file_path in tqdm(json_files, desc="íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
            
            reviews_list = raw_data.get('reviews', [])
            if not reviews_list: continue

            valid_reviews = []
            target_reviews = reviews_list[:50]

            for review in target_reviews:
                combined_parts = []
                if isinstance(review, dict):
                    if review.get('nose'): combined_parts.append(f"Nose: {review.get('nose')}")
                    if review.get('taste'): combined_parts.append(f"Taste: {review.get('taste')}")
                    if review.get('finish'): combined_parts.append(f"Finish: {review.get('finish')}")
                    if review.get('content'): combined_parts.append(f"Comment: {review.get('content')}")
                    full_text = "\n".join(combined_parts)
                else:
                    full_text = str(review)

                if len(full_text) < 5: continue
                if any(d.get('review_text') == full_text for d in training_data):
                    continue
                valid_reviews.append(full_text)

            for i in range(0, len(valid_reviews), BATCH_SIZE):
                batch = valid_reviews[i : i + BATCH_SIZE]
                if not batch: continue
                
                batch_results = analyze_batch_reviews(batch)
                
                for review_text, result in zip(batch, batch_results):
                    combined_data = {
                        "file_name": os.path.basename(file_path),
                        "original_name": raw_data.get("name", "Unknown"),
                        "review_text": review_text,
                        **result
                    }
                    training_data.append(combined_data)

                pd.DataFrame(training_data).to_csv(save_path, index=False, encoding='utf-8-sig')
                time.sleep(5)

        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì—ëŸ¬ ({os.path.basename(file_path)}): {e}")
            continue

    print(f"\nğŸ‰ ì™„ë£Œ! ì´ {len(training_data)}ê°œ ë°ì´í„°.")
    print(f"ì €ì¥ ìœ„ì¹˜: {save_path}")